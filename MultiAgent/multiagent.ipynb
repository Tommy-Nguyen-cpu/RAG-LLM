{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mFitness Researcher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mProvided the context and query below, answer the query using the context as necessary.\n",
      "  Ensure the information you provide is factual and accurate.\n",
      "  \n",
      "  Context: \n",
      "\n",
      "  User query: What is the best source of protein?\n",
      "  \u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mFitness Researcher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Your final answer must be the great and the most complete as possible, it must be outcome described.\n",
      "\n",
      "**The Best Source of Protein: A Comprehensive Analysis**\n",
      "\n",
      "Protein is an essential macronutrient that plays a critical role in building and repairing muscles, organs, and tissues in the body. With numerous food sources available, determining the best source of protein can be overwhelming. Here's a detailed analysis of various protein-rich foods to help you make an informed decision:\n",
      "\n",
      "**Animal-Based Protein Sources:**\n",
      "\n",
      "• **Lean Meats:** Chicken breast, turkey breast, lean beef, and pork tenderloin are excellent sources of protein, with approximately 30-40 grams of protein per 3-ounce serving.\n",
      "• **Fish and Seafood:** Fatty fish like salmon, tuna, and mackerel are high in protein and omega-3 fatty acids. Shrimp, scallops, and lobster are also rich in protein, with about 20-25 grams per 3-ounce serving.\n",
      "• **Eggs:** Eggs are an excellent source of protein, with about 6-7 grams of protein per large egg.\n",
      "• **Dairy:** Greek yogurt, cottage cheese, milk, and whey protein powder are all high in protein, with approximately 15-20 grams of protein per cup.\n",
      "\n",
      "**Plant-Based Protein Sources:**\n",
      "\n",
      "• **Legumes:** Beans, lentils, and chickpeas are rich in protein and fiber, with about 15-18 grams of protein per cup.\n",
      "• **Nuts and Seeds:** Almonds, chia seeds, hemp seeds, and pumpkin seeds are all high in protein, with approximately 5-8 grams of protein per ounce.\n",
      "• **Whole Grains:** Quinoa, farro, and bulgur are good sources of protein, with about 6-8 grams of protein per cup.\n",
      "• **Soy Products:** Tofu, tempeh, and edamame are popular plant-based protein sources, with approximately 10-15 grams of protein per 3-ounce serving.\n",
      "\n",
      "**Supplements:**\n",
      "\n",
      "• **Whey Protein Powder:** A fast-digesting protein powder that is high in branched-chain amino acids (BCAAs) and essential amino acids.\n",
      "• **Casein Protein Powder:** A slow-digesting protein powder that promotes muscle growth and recovery during sleep.\n",
      "• **Plant-Based Protein Powders:** Pea, rice, and hemp protein powders are popular alternatives to whey and casein.\n",
      "\n",
      "**Other Considerations:**\n",
      "\n",
      "• **Protein Content per Serving:** The amount of protein in a serving can vary greatly between foods. Aim for 0.8-1 gram of protein per pound of body weight daily.\n",
      "• **Allergies and Intolerances:** Be aware of potential allergies or intolerances to certain protein sources, such as lactose intolerance or shellfish allergies.\n",
      "• **Sustainability and Environmental Impact:** Choose protein-rich foods that are sustainably sourced and have a lower environmental impact.\n",
      "\n",
      "In conclusion, the best source of protein depends on individual needs, dietary preferences, and lifestyle. A balanced diet that includes a variety of protein-rich foods can provide all the necessary amino acids for optimal health and muscle growth. Always consult with a healthcare professional or registered dietitian to determine the best protein plan for your specific needs.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSports Advisor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mGiven the advice produced by Fitness Researcher, verify the advise and add on any missing information the Fitness Researcher may have missed.\n",
      "  Format your response in an engaging and educational manner while being elaborate. Try not to be too technical as to avoid sounding too much like an AI.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSports Advisor\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**Verifying Fitness Researcher's Advice**\n",
      "\n",
      "When Fitness Researcher advises on the best source of protein, they consider various factors such as nutritional content, bioavailability, and individual needs. According to their research, the best sources of protein are those that provide a balanced mix of essential amino acids, fiber, and other beneficial nutrients.\n",
      "\n",
      "**Analyzing Animal-Based Protein Sources**\n",
      "\n",
      "Lean meats like chicken breast, turkey breast, lean beef, and pork tenderloin are excellent sources of protein. Fish and seafood, such as salmon, tuna, and shrimp, offer not only protein but also omega-3 fatty acids for added health benefits. Eggs are another great source of protein, with approximately 6-7 grams per large egg. Dairy products like Greek yogurt, cottage cheese, milk, and whey protein powder are also high in protein.\n",
      "\n",
      "**Plant-Based Protein Sources: A Closer Look**\n",
      "\n",
      "Legumes, nuts, seeds, whole grains, and soy products offer a wealth of plant-based protein options. Legumes such as beans, lentils, and chickpeas provide not only protein but also fiber, vitamins, and minerals. Nuts and seeds like almonds, chia seeds, hemp seeds, and pumpkin seeds are rich in protein and healthy fats. Whole grains like quinoa, farro, and bulgur offer a good source of protein, while soy products such as tofu, tempeh, and edamame provide a complete protein.\n",
      "\n",
      "**Supplements: A Convenient Option**\n",
      "\n",
      "Whey protein powder, casein protein powder, and plant-based protein powders are popular options for those looking to supplement their diet. Whey protein powder is fast-digesting and high in branched-chain amino acids (BCAAs) and essential amino acids, while casein protein powder promotes muscle growth and recovery during sleep. Plant-based protein powders like pea, rice, and hemp protein offer a convenient way to increase protein intake.\n",
      "\n",
      "**Other Considerations: Protein Content per Serving**\n",
      "\n",
      "The amount of protein in a serving can vary greatly between foods. Aim for 0.8-1 gram of protein per pound of body weight daily. Be aware of potential allergies or intolerances to certain protein sources, such as lactose intolerance or shellfish allergies. Choose protein-rich foods that are sustainably sourced and have a lower environmental impact.\n",
      "\n",
      "In conclusion, Fitness Researcher's advice on the best source of protein emphasizes the importance of variety, nutritional balance, and individual needs. By considering these factors and exploring different protein sources, individuals can make informed decisions about their diet and supplement routine.\u001b[00m\n",
      "\n",
      "\n",
      "######################\n",
      "**Verifying Fitness Researcher's Advice**\n",
      "\n",
      "When Fitness Researcher advises on the best source of protein, they consider various factors such as nutritional content, bioavailability, and individual needs. According to their research, the best sources of protein are those that provide a balanced mix of essential amino acids, fiber, and other beneficial nutrients.\n",
      "\n",
      "**Analyzing Animal-Based Protein Sources**\n",
      "\n",
      "Lean meats like chicken breast, turkey breast, lean beef, and pork tenderloin are excellent sources of protein. Fish and seafood, such as salmon, tuna, and shrimp, offer not only protein but also omega-3 fatty acids for added health benefits. Eggs are another great source of protein, with approximately 6-7 grams per large egg. Dairy products like Greek yogurt, cottage cheese, milk, and whey protein powder are also high in protein.\n",
      "\n",
      "**Plant-Based Protein Sources: A Closer Look**\n",
      "\n",
      "Legumes, nuts, seeds, whole grains, and soy products offer a wealth of plant-based protein options. Legumes such as beans, lentils, and chickpeas provide not only protein but also fiber, vitamins, and minerals. Nuts and seeds like almonds, chia seeds, hemp seeds, and pumpkin seeds are rich in protein and healthy fats. Whole grains like quinoa, farro, and bulgur offer a good source of protein, while soy products such as tofu, tempeh, and edamame provide a complete protein.\n",
      "\n",
      "**Supplements: A Convenient Option**\n",
      "\n",
      "Whey protein powder, casein protein powder, and plant-based protein powders are popular options for those looking to supplement their diet. Whey protein powder is fast-digesting and high in branched-chain amino acids (BCAAs) and essential amino acids, while casein protein powder promotes muscle growth and recovery during sleep. Plant-based protein powders like pea, rice, and hemp protein offer a convenient way to increase protein intake.\n",
      "\n",
      "**Other Considerations: Protein Content per Serving**\n",
      "\n",
      "The amount of protein in a serving can vary greatly between foods. Aim for 0.8-1 gram of protein per pound of body weight daily. Be aware of potential allergies or intolerances to certain protein sources, such as lactose intolerance or shellfish allergies. Choose protein-rich foods that are sustainably sourced and have a lower environmental impact.\n",
      "\n",
      "In conclusion, Fitness Researcher's advice on the best source of protein emphasizes the importance of variety, nutritional balance, and individual needs. By considering these factors and exploring different protein sources, individuals can make informed decisions about their diet and supplement routine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "# It can be a local model through Ollama / LM Studio or a remote\n",
    "# model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)\n",
    "\n",
    "# Define your agents with roles and goals\n",
    "researcher = Agent(\n",
    "  role='Fitness Researcher',\n",
    "  goal='Uncover leading fitness knowledge and advances.',\n",
    "  backstory=\"\"\"You work at a well-known fitness research institution.\n",
    "  Your expertise lies in identifying emerging trends in fitness and providing powerful fitness advice.\n",
    "  You have a knack for finding hidden information that can help individuals to grow in terms of power and athleticism.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  # You can pass an optional llm attribute specifying what model you wanna use.\n",
    "  llm= \"ollama/llama3.2\"\n",
    ")\n",
    "writer = Agent(\n",
    "  role='Sports Advisor',\n",
    "  goal='Craft compelling content on sports advancements ad advices.',\n",
    "  backstory=\"\"\"You are a renowned sports advisor, known for your insightful and engaging advices and articles.\n",
    "  You transform complex concepts and advices into compelling narratives.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True,\n",
    "  llm = \"ollama/llama3.2\"\n",
    ")\n",
    "\n",
    "# Create tasks for your agents\n",
    "task1 = Task(\n",
    "  description=\"\"\"Provided the context and query below, answer the query using the context as necessary.\n",
    "  Ensure the information you provide is factual and accurate.\n",
    "  \n",
    "  Context: {Context}\n",
    "\n",
    "  User query: {user_query}\n",
    "  \"\"\",\n",
    "  expected_output=\"Full analysis report in bullet points\",\n",
    "  agent=researcher\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "  description=\"\"\"Given the advice produced by Fitness Researcher, verify the advise and add on any missing information the Fitness Researcher may have missed.\n",
    "  Format your response in an engaging and educational manner while being elaborate. Try not to be too technical as to avoid sounding too much like an AI.\"\"\",\n",
    "  expected_output=\"Full response of at least 4 paragraphs\",\n",
    "  agent=writer\n",
    ")\n",
    "\n",
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  tasks=[task1, task2],\n",
    "  verbose=True,\n",
    "  process = Process.sequential\n",
    ")\n",
    "\n",
    "\n",
    "input_query = {\n",
    "    \"user_query\" : \"What is the best source of protein?\",\n",
    "    \"Context\" : \"\"\n",
    "}\n",
    "\n",
    "# Get your crew to work!\n",
    "result = crew.kickoff(inputs = input_query)\n",
    "\n",
    "print(\"######################\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw='To train an audio-driven face animation for real-time applications, we can follow a multi-step process that involves data collection, feature extraction, model training, and deployment. First, we need to collect a large dataset of audio files with corresponding face animations, which can be achieved through semi-supervised or unsupervised learning methods.\\n\\nNext, we extract features from the audio files using techniques such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which can provide more accurate representations of the audio data. These features can be used to represent the audio data in a way that is useful for machine learning algorithms.\\n\\nAfter collecting and preprocessing the data, we can train a machine learning model using a supervised learning approach. A suitable algorithm for this task could be a CNN or RNN that takes the extracted audio features as input and predicts the corresponding face animation parameters.\\n\\nTo further improve the performance of the model, we can use techniques such as data augmentation, transfer learning, or ensemble methods to combine the predictions of multiple models. Additionally, we can incorporate additional cues from other sources, such as video or 3D facial reconstruction, to provide more accurate and realistic animations.\\n\\nOnce the model is trained and validated on a test dataset, we can deploy it in real-time applications using techniques such as streaming data processing, GPU acceleration, and edge computing. This will allow us to generate high-quality face animations in response to audio input in real-time, enabling applications such as virtual reality, gaming, or social media.\\n\\nTo handle variability and uncertainty present in real-world audio data, we can use techniques such as noise reduction, signal processing, or machine learning-based audio enhancement to improve the quality of the input audio data. We can also explore more advanced methods, such as wavelet denoising or deep learning-based audio enhancement, to further optimize the performance.\\n\\nIn terms of specific applications, an audio-driven face animation system could be used in a variety of contexts, such as virtual reality or gaming applications that require realistic character animations. It could also be integrated into social media platforms, e-commerce websites, or mobile apps to provide more engaging and personalized user experiences.\\n\\nOverall, training an audio-driven face animation for real-time applications requires careful consideration of data collection, feature extraction, model training, and deployment. By leveraging machine learning algorithms, incorporating additional cues from other sources, and optimizing the deployment process, we can create highly effective systems that generate high-quality face animations in response to audio input in real-time.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Solve the problem provided: How do I train an audio driven face animation for real-time applications?', name=None, expected_output='Full paragraphs explaining process.', summary='Solve the problem provided: How do I train an audio...', raw=\"To train an audio-driven face animation for real-time applications, we can follow a multi-step process that involves data collection, feature extraction, model training, and deployment. First, we need to collect a large dataset of audio files with corresponding face animations. This dataset can be created by recording individuals speaking or making various facial expressions while wearing a webcam or other video capture device.\\n\\nNext, we extract features from the audio files using techniques such as Mel-frequency cepstral coefficients (MFCCs) or spectrograms. These features can be used to represent the audio data in a way that is useful for machine learning algorithms. We can also use additional features such as lip movement tracking, facial landmarks, or 3D face reconstruction to provide more context for the animation.\\n\\nAfter collecting and preprocessing the data, we can train a machine learning model using a supervised learning approach. A suitable algorithm for this task could be a deep neural network, such as a convolutional neural network (CNN) or recurrent neural network (RNN), that takes the extracted audio features as input and predicts the corresponding face animation parameters.\\n\\nThe CNN can learn to recognize patterns in the audio data that correspond to different facial expressions, emotions, or speech styles. The RNN can be trained to model temporal relationships between frames of the animation, allowing it to generate smooth and realistic animations.\\n\\nTo further improve the performance of the model, we can use techniques such as data augmentation, transfer learning, or ensemble methods to combine the predictions of multiple models. Additionally, we can incorporate additional cues from other sources, such as video or 3D facial reconstruction, to improve the accuracy and robustness of the face animation.\\n\\nOnce the model is trained and validated on a test dataset, we can deploy it in real-time applications using techniques such as streaming data processing, GPU acceleration, or edge computing. This will allow us to generate high-quality face animations in response to audio input in real-time, enabling applications such as virtual reality, gaming, or social media.\\n\\nOne of the key challenges in training an audio-driven face animation for real-time applications is handling the variability and uncertainty present in real-world audio data. To address this challenge, we can use techniques such as noise reduction, signal processing, or machine learning-based audio enhancement to improve the quality of the input audio data.\\n\\nAnother important consideration is the trade-off between model performance and computational complexity. As the number of parameters in the model increases, so does its computational complexity, which can lead to slower inference times and increased memory requirements. Therefore, it's essential to carefully evaluate the balance between model performance and complexity when selecting an algorithm for this task.\\n\\nIn terms of specific applications, an audio-driven face animation system could be used in a variety of contexts, such as virtual reality or gaming applications that require realistic character animations. It could also be integrated into social media platforms, e-commerce websites, or mobile apps to provide more engaging and personalized user experiences.\\n\\nOverall, training an audio-driven face animation for real-time applications requires careful consideration of data collection, feature extraction, model training, and deployment. By leveraging machine learning algorithms and incorporating additional cues from other sources, we can create highly effective systems that generate high-quality face animations in response to audio input in real-time.\", pydantic=None, json_dict=None, agent='Principal Software Engineer', output_format=<OutputFormat.RAW: 'raw'>), TaskOutput(description='Solve the problem provided: How do I train an audio driven face animation for real-time applications?. Given answer from Principal Software Engineer, improve upon it and find any possible flaws.', name=None, expected_output='Full paragraphs explaining process.', summary='Solve the problem provided: How do I train an audio...', raw='To train an audio-driven face animation for real-time applications, we can follow a multi-step process that involves data collection, feature extraction, model training, and deployment. First, we need to collect a large dataset of audio files with corresponding face animations, which can be achieved through semi-supervised or unsupervised learning methods.\\n\\nNext, we extract features from the audio files using techniques such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), which can provide more accurate representations of the audio data. These features can be used to represent the audio data in a way that is useful for machine learning algorithms.\\n\\nAfter collecting and preprocessing the data, we can train a machine learning model using a supervised learning approach. A suitable algorithm for this task could be a CNN or RNN that takes the extracted audio features as input and predicts the corresponding face animation parameters.\\n\\nTo further improve the performance of the model, we can use techniques such as data augmentation, transfer learning, or ensemble methods to combine the predictions of multiple models. Additionally, we can incorporate additional cues from other sources, such as video or 3D facial reconstruction, to provide more accurate and realistic animations.\\n\\nOnce the model is trained and validated on a test dataset, we can deploy it in real-time applications using techniques such as streaming data processing, GPU acceleration, and edge computing. This will allow us to generate high-quality face animations in response to audio input in real-time, enabling applications such as virtual reality, gaming, or social media.\\n\\nTo handle variability and uncertainty present in real-world audio data, we can use techniques such as noise reduction, signal processing, or machine learning-based audio enhancement to improve the quality of the input audio data. We can also explore more advanced methods, such as wavelet denoising or deep learning-based audio enhancement, to further optimize the performance.\\n\\nIn terms of specific applications, an audio-driven face animation system could be used in a variety of contexts, such as virtual reality or gaming applications that require realistic character animations. It could also be integrated into social media platforms, e-commerce websites, or mobile apps to provide more engaging and personalized user experiences.\\n\\nOverall, training an audio-driven face animation for real-time applications requires careful consideration of data collection, feature extraction, model training, and deployment. By leveraging machine learning algorithms, incorporating additional cues from other sources, and optimizing the deployment process, we can create highly effective systems that generate high-quality face animations in response to audio input in real-time.', pydantic=None, json_dict=None, agent='Principal Software Engineer', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=5014, prompt_tokens=1985, completion_tokens=3029, successful_requests=3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from single_agent import SingleAgent\n",
    "from single_task import SingleTask\n",
    "from crewai import Crew\n",
    "\n",
    "agent1 = SingleAgent(\"Principal Software Engineer\", \"Find bugs in program and suggests innovative ideas.\", \"\"\"\n",
    "You are a principal software engineer from Google. You are highly skilled and knowledgeable in software engineer.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "agent2 = SingleAgent(\"Principal Software Engineer\", \"Find bugs in program and suggests innovative ideas.\", \"\"\"\n",
    "You are a principal software engineer from Google. You are highly skilled and knowledgeable in software engineer.\n",
    "\"\"\")\n",
    "\n",
    "task1 = SingleTask(\"Solve the problem provided: {user_query}\", \"Full paragraphs explaining process.\", agent1.agent)\n",
    "task2 = SingleTask(\"Solve the problem provided: {user_query}. Given answer from Principal Software Engineer, improve upon it and find any possible flaws.\", \"Full paragraphs explaining process.\", agent2.agent)\n",
    "\n",
    "crew = Crew(agents = [agent1.agent, agent2.agent], tasks = [task1.task, task2.task])\n",
    "\n",
    "crew.kickoff(inputs = {\"user_query\" : \"How do I train an audio driven face animation for real-time applications?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"context.txt\", \"a\") as f:\n",
    "    query = \"What are you doing?\"\n",
    "    result = crew.kickoff(inputs = {\"user_query\" : query})\n",
    "\n",
    "    f.write(f\"User query: {query}\" + \"\\n\" + \"Response: \" + result.tasks_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "prompt = lambda user_input, context: f\"\"\"\n",
    "You are my personal assistant who specializes in computer science. Using the context given below, answer to my query using the context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "My query: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"What is your name?\"\n",
    "top_k = 5\n",
    "\n",
    "model_name = \"Qwen/Qwen2-1.5B\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(model_name, device_map = \"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)\n",
    "\n",
    "sentence_encoder = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "with open(\"context.txt\", \"r+\") as f:\n",
    "    context_doc = f.read()\n",
    "    context_paragraphs = context_doc.split(\"\\n\\n\")\n",
    "\n",
    "    context_embedding = sentence_encoder.encode(context_paragraphs, normalize_embeddings = True)\n",
    "    input_embedding = sentence_encoder.encode(user_query, normalize_embeddings = True)\n",
    "    similarities = np.dot(context_embedding, input_embedding.T) # Calculate similarity scores.\n",
    "    top_k_indices = np.argsort(similarities)[::-1][::top_k] # Sort from greatest to least and grab top_k greatest.\n",
    "\n",
    "    top_k_context = np.array(context_paragraphs)[top_k_indices] # Grab top_k indices.\n",
    "    \n",
    "    # Creates context string.\n",
    "    context = \"\"\n",
    "    for para in top_k_context:\n",
    "        context += para + \"\\n\\n\"\n",
    "\n",
    "    my_input = prompt(user_query, context)\n",
    "\n",
    "    tokens = tokenizer(my_input, return_tensors=\"pt\")\n",
    "    result = tokenizer.decode(llm.generate(input_ids = tokens[\"input_ids\"], max_new_tokens = 200)[0])\n",
    "    print(result)\n",
    "\n",
    "    new_subcontext = f\"User query: {user_query}\\nMy response: {result}\"\n",
    "    f.write(new_subcontext)\n",
    "    context_paragraphs.append(new_subcontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "prompt = lambda user_input, context: f\"\"\"\n",
    "You are my personal assistant who specializes in computer science. Using the context given below, answer to my query using the context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "My query: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"What is your name?\"\n",
    "top_k = 5\n",
    "\n",
    "model_name = \"Qwen/Qwen2-1.5B\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(model_name, device_map = \"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)\n",
    "\n",
    "sentence_encoder = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "with open(\"context.txt\", \"r+\") as f:\n",
    "    context_doc = f.read()\n",
    "    context_paragraphs = context_doc.split(\"\\n\\n\")\n",
    "\n",
    "    context_embedding = sentence_encoder.encode(context_paragraphs, normalize_embeddings = True)\n",
    "    input_embedding = sentence_encoder.encode(user_query, normalize_embeddings = True)\n",
    "    similarities = np.dot(context_embedding, input_embedding.T) # Calculate similarity scores.\n",
    "    top_k_indices = np.argsort(similarities)[::-1][::top_k] # Sort from greatest to least and grab top_k greatest.\n",
    "\n",
    "    top_k_context = np.array(context_paragraphs)[top_k_indices] # Grab top_k indices.\n",
    "    \n",
    "    # Creates context string.\n",
    "    context = \"\"\n",
    "    for para in top_k_context:\n",
    "        context += para + \"\\n\\n\"\n",
    "\n",
    "    my_input = prompt(user_query, context)\n",
    "\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": my_input}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(llm.device)\n",
    "\n",
    "    generated_ids = llm.generate(**model_inputs, max_new_tokens = 200)\n",
    "    # generated_ids = [\n",
    "    # output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    # ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    new_subcontext = f\"User query: {user_query}\\nMy response: {response}\"\n",
    "    f.write(new_subcontext)\n",
    "    context_paragraphs.append(new_subcontext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
