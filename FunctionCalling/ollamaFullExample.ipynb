{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarkItDown\n",
    "Wanted to see if we could use MarkItDown to make the resume better fit expected input of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown._markitdown import PdfConverter\n",
    "\n",
    "md = PdfConverter()\n",
    "resume_markdown = md.convert(\"Tommy Nguyen Resume 2 Pages.pdf\", file_extension = \".pdf\")\n",
    "\n",
    "markup_text = resume_markdown.text_content.replace(\"• \", \"\").replace(\"• \\n\", \"\")\n",
    "\n",
    "print(markup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"Tommy Nguyen Resume 2 Pages.pdf\")\n",
    "\n",
    "print(len(reader.pages))\n",
    "\n",
    "final_resume_text = \"\"\n",
    "\n",
    "for page_num in range(len(reader.pages)):\n",
    "    resulting_text = reader.pages[page_num].extract_text()\n",
    "\n",
    "    # Removing all \"comments\" brought over from Word to PDF when converting. Forgot to remove them beforehand. Preprocessing the text here.\n",
    "    resulting_list = resulting_text.split(\"\\n\")\n",
    "    for i in range(len(resulting_list)):\n",
    "        index_of_comments = resulting_list[i].lower().find(\"comment\")\n",
    "        if index_of_comments >= 0:\n",
    "            resulting_list[i] = resulting_list[i].replace(resulting_list[i][index_of_comments:-1], \"\")\n",
    "\n",
    "        string_check = resulting_list[i].lower().strip()\n",
    "        if \"graduated august 2023...\" in string_check or \"undergraduate courses.\"  == string_check or \"https://www.indeed.com/career -advice/resumes\"  in string_check or \"how did you mentor them?\"  in string_check or \"letters/how -to-list-publications -on-resume\" in string_check or \"another subsection as personal.\" == string_check:\n",
    "            resulting_list[i] = None\n",
    "    \n",
    "    # TODO: There's still a ton of whitespaces between some parts, most likely due to page breaks.\n",
    "    processed_text = \"\\n\".join([item for item in resulting_list if item is not None ])\n",
    "\n",
    "    if final_resume_text != \"\":\n",
    "        final_resume_text += \"\\n\\n\" + processed_text\n",
    "    else:\n",
    "        final_resume_text += processed_text\n",
    "    # print(f\"Page {page_num}:\\n{processed_text}\")\n",
    "\n",
    "print(f\"Final extracted text:\\n{final_resume_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping For Job Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# User input\n",
    "keyword = [\"Software Engineer\", \"Amazon\"]\n",
    "location = \"Boston, MA\"\n",
    "\n",
    "# Constants/Fields\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
    "\n",
    "SPACE_REPLACER = \"%20\"\n",
    "COMMA_REPLACER = \"%2C\"\n",
    "\n",
    "class LinkedinScraper():\n",
    "    def __init__(self):\n",
    "        self.output_url = \"https://www.linkedin.com/jobs/search/?currentJobId={}\"\n",
    "        self.results_context_class = \"results-context-header\"\n",
    "        self.results_context_tag_type = \"div\"\n",
    "\n",
    "        self.job_count_class = \"results-context-header__job-count\"\n",
    "        self.job_count_tag_type = \"span\"\n",
    "\n",
    "        self.keyword_query = \"\"\n",
    "        self.location_query = \"\"\n",
    "        self.target_url = \"\"\n",
    "\n",
    "    def set_keyword_and_locations(self, keyword : list[str], location : str):\n",
    "        \"\"\"\n",
    "        Sets up urls for GET API requests.\n",
    "\n",
    "        Args:\n",
    "            keyword: list of strings containing specific keywords to search for in a job.\n",
    "            location: Desired location for the job.\n",
    "        \"\"\"\n",
    "        self.keyword_query = f\"{COMMA_REPLACER}{SPACE_REPLACER}\".join(keyword).replace(\",\", COMMA_REPLACER).replace(\" \", SPACE_REPLACER)\n",
    "        self.location_query = location.replace(\",\", COMMA_REPLACER).replace(\" \", SPACE_REPLACER)\n",
    "        url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={self.keyword_query}&location={self.location_query}\"\n",
    "        self.target_url= url + '&geoId=&currentJobId=&start={}'\n",
    "\n",
    "    def get_job_counter(self) -> int:\n",
    "        \"\"\"\n",
    "        Retrieves the number of jobs found for the particular search. Used by \"get_jobs\" to determine number of iterations.\n",
    "        \"\"\"\n",
    "        job_counter_url = f\"https://www.linkedin.com/jobs/search?keywords={self.keyword_query}&location={self.location_query}&geoId=&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\"\n",
    "        \n",
    "        request = requests.get(job_counter_url)\n",
    "        soup1 = BeautifulSoup(request.text, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            num_jobs_found = soup1.find_all(self.results_context_tag_type, {\"class\" : self.results_context_class})[0].find(self.job_count_tag_type, {\"class\" : self.job_count_class}).text\n",
    "            num_jobs_found = num_jobs_found.replace(\"+\", \"\").replace(\",\", \"\")\n",
    "        except:\n",
    "            raise Exception(\"The 'Job Counter' tag was not found! LinkedIn must have changed it...\")\n",
    "        \n",
    "        if not num_jobs_found or not num_jobs_found.isdigit():\n",
    "            raise Exception(f\"Either the returned job counter is invalid or the search is too broad! Job Counter: {num_jobs_found}\")\n",
    "\n",
    "        return int(num_jobs_found)\n",
    "\n",
    "    def get_jobs(self, keyword : list[str] = [\"Software Engineer\"], location : str = \"Boston\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves job listings from LinkedIn based on keyword and location search.\n",
    "\n",
    "        Args:\n",
    "            keyword: list of strings containing specific keywords to search for in a job.\n",
    "            location: Desired location for the job.\n",
    "        Returns:\n",
    "            DataFrame: A dataframe containing all relevant jobs to search.\n",
    "        \"\"\"\n",
    "        self.set_keyword_and_locations(keyword, location)\n",
    "\n",
    "        num_jobs = self.get_job_counter()\n",
    "        job_ids=[]\n",
    "        job_info={}\n",
    "        jobs=[]\n",
    "        for i in range(0,math.ceil(num_jobs/25)):\n",
    "\n",
    "            res = requests.get(self.target_url.format(i))\n",
    "            soup=BeautifulSoup(res.text,'html.parser')\n",
    "            alljobs_on_this_page=soup.find_all(\"li\")\n",
    "            # print(len(alljobs_on_this_page))\n",
    "            for x in range(0,len(alljobs_on_this_page)):\n",
    "                jobid = alljobs_on_this_page[x].find(\"div\",{\"class\":\"base-card\"}).get('data-entity-urn').split(\":\")[3]\n",
    "                job_ids.append(jobid)\n",
    "\n",
    "        specific_job_url='https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}'\n",
    "        for j in range(0,len(job_ids)):\n",
    "\n",
    "            resp = requests.get(specific_job_url.format(job_ids[j]))\n",
    "            soup=BeautifulSoup(resp.text,'html.parser')\n",
    "\n",
    "            try:\n",
    "                job_info[\"company\"]=soup.find(\"div\",{\"class\":\"top-card-layout__card\"}).find(\"a\").find(\"img\").get('alt')\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                a_tag = soup.find(\"div\",{\"class\":\"top-card-layout__entity-info\"}).find(\"a\")\n",
    "                job_info[\"job-title\"] = a_tag.text.strip()\n",
    "            except:\n",
    "                job_info[\"job-title\"]=None\n",
    "            \n",
    "            try:\n",
    "                job_description = soup.find(\"div\", {\"class\" : \"description__text description__text--rich\"}).text.lstrip(\"\\n\") \n",
    "                job_info[\"job-description\"] = job_description\n",
    "            except:\n",
    "                job_info[\"job-description\"] = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                job_info[\"pay-range\"] = soup.find(\"div\", {\"class\" : \"compensation__salary-range\"}).find(\"div\", {\"class\" : \"salary compensation__salary\"}).text\n",
    "            except:\n",
    "                job_info[\"pay-range\"] = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                job_info[\"level\"]=soup.find(\"ul\",{\"class\":\"description__job-criteria-list\"}).find(\"li\").text.replace(\"Seniority level\",\"\").strip()\n",
    "            except:\n",
    "                job_info[\"level\"]=None\n",
    "\n",
    "            job_info[\"job-link\"] = self.output_url.format(job_ids[j])\n",
    "\n",
    "            jobs.append(job_info)\n",
    "            job_info={}\n",
    "\n",
    "        df = pd.DataFrame(jobs)\n",
    "        # df.to_csv('linkedinjobs.csv', index=False, encoding='utf-8')\n",
    "        # print(df)\n",
    "        return df\n",
    "\n",
    "linkedinObj = LinkedinScraper()\n",
    "linkedinObj.get_jobs([\"Software Engineer\", \"Apple\", \"Python\"], \"Boston, MA\").to_csv(\"jobs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
