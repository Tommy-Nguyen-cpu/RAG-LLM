{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarkItDown\n",
    "Wanted to see if we could use MarkItDown to make the resume better fit expected input of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown._markitdown import PdfConverter\n",
    "\n",
    "md = PdfConverter()\n",
    "resume_markdown = md.convert(\"Tommy Nguyen Resume 2 Pages.pdf\", file_extension = \".pdf\")\n",
    "\n",
    "markup_text = resume_markdown.text_content.replace(\"• \", \"\").replace(\"• \\n\", \"\")\n",
    "\n",
    "print(markup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"Tommy Nguyen Resume 2 Pages.pdf\")\n",
    "\n",
    "print(len(reader.pages))\n",
    "\n",
    "final_resume_text = \"\"\n",
    "\n",
    "for page_num in range(len(reader.pages)):\n",
    "    resulting_text = reader.pages[page_num].extract_text()\n",
    "\n",
    "    # Removing all \"comments\" brought over from Word to PDF when converting. Forgot to remove them beforehand. Preprocessing the text here.\n",
    "    resulting_list = resulting_text.split(\"\\n\")\n",
    "    for i in range(len(resulting_list)):\n",
    "        index_of_comments = resulting_list[i].lower().find(\"comment\")\n",
    "        if index_of_comments >= 0:\n",
    "            resulting_list[i] = resulting_list[i].replace(resulting_list[i][index_of_comments:-1], \"\")\n",
    "\n",
    "        string_check = resulting_list[i].lower().strip()\n",
    "        if \"graduated august 2023...\" in string_check or \"undergraduate courses.\"  == string_check or \"https://www.indeed.com/career -advice/resumes\"  in string_check or \"how did you mentor them?\"  in string_check or \"letters/how -to-list-publications -on-resume\" in string_check or \"another subsection as personal.\" == string_check:\n",
    "            resulting_list[i] = None\n",
    "    \n",
    "    # TODO: There's still a ton of whitespaces between some parts, most likely due to page breaks.\n",
    "    processed_text = \"\\n\".join([item for item in resulting_list if item is not None ])\n",
    "\n",
    "    if final_resume_text != \"\":\n",
    "        final_resume_text += \"\\n\\n\" + processed_text\n",
    "    else:\n",
    "        final_resume_text += processed_text\n",
    "    # print(f\"Page {page_num}:\\n{processed_text}\")\n",
    "\n",
    "print(f\"Final extracted text:\\n{final_resume_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping For Job Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
    "l=[]\n",
    "o={}\n",
    "k=[]\n",
    "space_replacer = \"%20\"\n",
    "comma_replacer = \"%2C\"\n",
    "\n",
    "keyword = [\"Software Engineer\", \"Amazon\"]\n",
    "location = \"Boston, MA\"\n",
    "\n",
    "keyword_query = f\"{comma_replacer}{space_replacer}\".join(keyword).replace(\",\", comma_replacer).replace(\" \", space_replacer)\n",
    "location_query = location.replace(\",\", comma_replacer).replace(\" \", space_replacer)\n",
    "\n",
    "print(keyword_query)\n",
    "print(location_query)\n",
    "\n",
    "url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={keyword_query}&location={location_query}\"\n",
    "target_url= url + '&geoId=&currentJobId=&start={}'\n",
    "\n",
    "request = requests.get(f\"https://www.linkedin.com/jobs/search?keywords={keyword_query}&location={location_query}&geoId=&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\")\n",
    "soup1 = BeautifulSoup(request.text, \"html.parser\")\n",
    "print(f\"https://www.linkedin.com/jobs/search?keywords={keyword_query}&location={location_query}&geoId=&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\")\n",
    "\n",
    "results_context_class = \"results-context-header\"\n",
    "results_context_tag_type = \"div\"\n",
    "\n",
    "job_count_class = \"results-context-header__job-count\"\n",
    "job_count_tag_type = \"span\"\n",
    "try:\n",
    "    num_jobs_found = soup1.find_all(results_context_tag_type, {\"class\" : results_context_class})[0].find(job_count_tag_type, {\"class\" : job_count_class}).text\n",
    "except:\n",
    "    raise Exception(\"The 'Job Counter' tag was not found! LinkedIn must have changed it...\")\n",
    "\n",
    "if not num_jobs_found or not num_jobs_found.isdigit():\n",
    "    raise Exception(\"The returned job counter is invalid!\")\n",
    "\n",
    "num_jobs = int(num_jobs_found)\n",
    "for i in range(0,math.ceil(num_jobs/25)):\n",
    "\n",
    "    res = requests.get(target_url.format(i))\n",
    "    soup=BeautifulSoup(res.text,'html.parser')\n",
    "    alljobs_on_this_page=soup.find_all(\"li\")\n",
    "    print(len(alljobs_on_this_page))\n",
    "    for x in range(0,len(alljobs_on_this_page)):\n",
    "        jobid = alljobs_on_this_page[x].find(\"div\",{\"class\":\"base-card\"}).get('data-entity-urn').split(\":\")[3]\n",
    "        l.append(jobid)\n",
    "\n",
    "target_url='https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}'\n",
    "for j in range(0,len(l)):\n",
    "\n",
    "    resp = requests.get(target_url.format(l[j]))\n",
    "    soup=BeautifulSoup(resp.text,'html.parser')\n",
    "\n",
    "    try:\n",
    "        o[\"company\"]=soup.find(\"div\",{\"class\":\"top-card-layout__card\"}).find(\"a\").find(\"img\").get('alt')\n",
    "    except:\n",
    "        o[\"company\"]=None\n",
    "\n",
    "    try:\n",
    "        o[\"job-title\"]=soup.find(\"div\",{\"class\":\"top-card-layout__entity-info\"}).find(\"a\").text.strip()\n",
    "    except:\n",
    "        o[\"job-title\"]=None\n",
    "\n",
    "    try:\n",
    "        o[\"level\"]=soup.find(\"ul\",{\"class\":\"description__job-criteria-list\"}).find(\"li\").text.replace(\"Seniority level\",\"\").strip()\n",
    "    except:\n",
    "        o[\"level\"]=None\n",
    "\n",
    "\n",
    "\n",
    "    k.append(o)\n",
    "    o={}\n",
    "\n",
    "df = pd.DataFrame(k)\n",
    "df.to_csv('linkedinjobs.csv', index=False, encoding='utf-8')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
